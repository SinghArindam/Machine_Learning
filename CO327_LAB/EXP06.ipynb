{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment No 06 : To implement decision tree using ID3 algorithm.\n"
     ]
    }
   ],
   "source": [
    "print(\"Experiment No 06 : To implement decision tree using ID3 algorithm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tOUTPUT:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal length (cm)': {1.0: 'setosa',\n",
      "                       1.1: 'setosa',\n",
      "                       1.2: 'setosa',\n",
      "                       1.3: 'setosa',\n",
      "                       1.4: 'setosa',\n",
      "                       1.5: 'setosa',\n",
      "                       1.6: 'setosa',\n",
      "                       1.7: 'setosa',\n",
      "                       1.9: 'setosa',\n",
      "                       3.0: 'versicolor',\n",
      "                       3.3: 'versicolor',\n",
      "                       3.5: 'versicolor',\n",
      "                       3.6: 'versicolor',\n",
      "                       3.7: 'versicolor',\n",
      "                       3.8: 'versicolor',\n",
      "                       3.9: 'versicolor',\n",
      "                       4.0: 'versicolor',\n",
      "                       4.1: 'versicolor',\n",
      "                       4.2: 'versicolor',\n",
      "                       4.3: 'versicolor',\n",
      "                       4.4: 'versicolor',\n",
      "                       4.5: {'sepal length (cm)': {4.9: 'virginica',\n",
      "                                                   5.4: 'versicolor',\n",
      "                                                   5.6: 'versicolor',\n",
      "                                                   5.7: 'versicolor',\n",
      "                                                   6.0: 'versicolor',\n",
      "                                                   6.2: 'versicolor',\n",
      "                                                   6.4: 'versicolor'}},\n",
      "                       4.6: 'versicolor',\n",
      "                       4.7: 'versicolor',\n",
      "                       4.8: {'sepal length (cm)': {5.9: 'versicolor',\n",
      "                                                   6.0: 'virginica',\n",
      "                                                   6.2: 'virginica',\n",
      "                                                   6.8: 'versicolor'}},\n",
      "                       4.9: {'sepal width (cm)': {2.5: 'versicolor',\n",
      "                                                  2.7: 'virginica',\n",
      "                                                  2.8: 'virginica',\n",
      "                                                  3.0: 'virginica',\n",
      "                                                  3.1: 'versicolor'}},\n",
      "                       5.0: {'sepal length (cm)': {5.7: 'virginica',\n",
      "                                                   6.0: 'virginica',\n",
      "                                                   6.3: 'virginica',\n",
      "                                                   6.7: 'versicolor'}},\n",
      "                       5.1: {'sepal length (cm)': {5.8: 'virginica',\n",
      "                                                   5.9: 'virginica',\n",
      "                                                   6.0: 'versicolor',\n",
      "                                                   6.3: 'virginica',\n",
      "                                                   6.5: 'virginica',\n",
      "                                                   6.9: 'virginica'}},\n",
      "                       5.2: 'virginica',\n",
      "                       5.3: 'virginica',\n",
      "                       5.4: 'virginica',\n",
      "                       5.5: 'virginica',\n",
      "                       5.6: 'virginica',\n",
      "                       5.7: 'virginica',\n",
      "                       5.8: 'virginica',\n",
      "                       5.9: 'virginica',\n",
      "                       6.0: 'virginica',\n",
      "                       6.1: 'virginica',\n",
      "                       6.3: 'virginica',\n",
      "                       6.4: 'virginica',\n",
      "                       6.6: 'virginica',\n",
      "                       6.7: 'virginica',\n",
      "                       6.9: 'virginica'}}\n",
      "\n",
      "\t Prediction for the first instance: setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\tOUTPUT:\\n\\n\")\n",
    "\n",
    "# Function to calculate entropy of a dataset\n",
    "def entropy(data):\n",
    "    total_count = len(data)\n",
    "    counts = Counter(data)\n",
    "    ent = 0\n",
    "    for count in counts.values():\n",
    "        prob = count / total_count\n",
    "        ent -= prob * np.log2(prob) if prob > 0 else 0\n",
    "    return ent\n",
    "\n",
    "# Function to calculate information gain for a feature\n",
    "def information_gain(data, feature):\n",
    "    total_entropy = entropy(data.iloc[:, -1])  # The target column is the last column\n",
    "    feature_values = data[feature].unique()\n",
    "    \n",
    "    weighted_entropy = 0\n",
    "    for value in feature_values:\n",
    "        subset = data[data[feature] == value]\n",
    "        weighted_entropy += (len(subset) / len(data)) * entropy(subset.iloc[:, -1])\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# Function to build the decision tree using ID3\n",
    "def id3(data, features):\n",
    "    # Base case: If all rows have the same class, return the class label\n",
    "    if len(set(data.iloc[:, -1])) == 1:\n",
    "        return data.iloc[0, -1]\n",
    "    \n",
    "    # Base case: If no features left to split, return the majority class label\n",
    "    if len(features) == 0:\n",
    "        return Counter(data.iloc[:, -1]).most_common(1)[0][0]\n",
    "    \n",
    "    # Select the feature with the highest information gain\n",
    "    gains = [information_gain(data, feature) for feature in features]\n",
    "    best_feature = features[np.argmax(gains)]\n",
    "    \n",
    "    # Create a decision tree node\n",
    "    tree = {best_feature: {}}\n",
    "    remaining_features = [feature for feature in features if feature != best_feature]\n",
    "    \n",
    "    # Split the data based on the selected feature and recursively build subtrees\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        subtree = id3(subset, remaining_features)\n",
    "        tree[best_feature][value] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Function to make predictions using the decision tree\n",
    "def predict(tree, instance):\n",
    "    if isinstance(tree, dict):\n",
    "        feature = list(tree.keys())[0]\n",
    "        value = instance[feature]\n",
    "        subtree = tree[feature].get(value)\n",
    "        return predict(subtree, instance)\n",
    "    else:\n",
    "        return tree\n",
    "\n",
    "# Example of how to use ID3 to classify the Iris dataset\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load Iris dataset and create DataFrame\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['species'] = iris.target\n",
    "\n",
    "# Convert the numeric target values to actual species names for better readability\n",
    "data['species'] = data['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# Features to consider for splitting (excluding the target variable)\n",
    "features = data.columns[:-1]  # Extract feature column names\n",
    "\n",
    "# Build the decision tree using ID3\n",
    "tree = id3(data, features)\n",
    "\n",
    "# Print the decision tree\n",
    "import pprint\n",
    "pprint.pprint(tree)\n",
    "\n",
    "# Making predictions on a new instance (just an example)\n",
    "new_instance = data.iloc[0]  # You can choose any instance to test\n",
    "prediction = predict(tree, new_instance)\n",
    "print(f\"\\n\\t Prediction for the first instance: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
